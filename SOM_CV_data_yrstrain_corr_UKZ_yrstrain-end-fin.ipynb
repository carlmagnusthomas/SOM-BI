{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## SOM_CV_data_yrstrain_UKESM\n",
    "# \n",
    "# This notebook trains the SOMs from the input data where there is a given GTD (either era5 or UK-ESM-1-0-LL piControl). From a specified number of folds in the cross-validation, the function trains and plots the SOM and associated trends from the training data. The SOM is then applied to the test dataset. This is done for each specified set of years.\n",
    "# \n",
    "# \n",
    "# This notebook looks at varying the number of years in the test dataset with a constant number of years trained over, so that by seeing the change in F1 score over time we can identify the minimum number of years needed to constrain the blocking climatology\n",
    "# \n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\", warn=False)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = \"/rds/general/user/kc1116/home/anaconda3/envs/zeus/share/proj\"\n",
    "import matplotlib as mpl\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import somoclu\n",
    "import cartopy\n",
    "import xarray\n",
    "import xarray as xr\n",
    "import glob\n",
    "import math\n",
    "from mpl_toolkits.basemap import Basemap as bm\n",
    "from itertools import groupby\n",
    "from scipy import stats\n",
    "import cartopy.crs as ccrs\n",
    "from statsmodels.stats.multitest import (multipletests, fdrcorrection,\n",
    "                                         fdrcorrection_twostage,\n",
    "                                         NullDistribution,\n",
    "                                         local_fdr)\n",
    "from scipy.stats import spearmanr, kendalltau, pearsonr\n",
    "from functools import wraps\n",
    "import errno\n",
    "import os\n",
    "import signal\n",
    "import SOM_trends_funcs as SOM_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_JJA_extd(da):\n",
    "    \"\"\"\n",
    "    Selects the JJA extd period +- 5 days.\n",
    "    \"\"\"\n",
    "    da_MJJAS=da.sel(time = np.isin(da['time.month'], np.arange(5,10)))\n",
    "    da_JJAextdS=da_MJJAS.sel(time=~(((da_MJJAS.time.dt.month == 5) & (da_MJJAS.time.dt.day < 28))))\n",
    "    da_JJAextd=da_JJAextdS.sel(time=~(((da_JJAextdS.time.dt.month == 9) & (da_JJAextdS.time.dt.day > 4))))\n",
    "    return da_JJAextd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_SOM_data(zg_file, yrst, yrend, season, region, init, neigh, std, ep, rad_0, rad_N, rad_cooling, scale_0, scale_N, scale_cooling,\n",
    "            savefig_title, savefig_trends, n_rows, n_columns, samp, zg_str, colormap_str, suptitle, mult_test_method, #yrst=1979, yrend=2013\n",
    "                data_yr_reshaped, vmin, vmax, step, lat_str, lon_str, units, mdl, train_input = False, som_yr = None, JJA_days=104, save_SOM_str = False, save_SOM_trends_str = False):\n",
    "    \"\"\"\n",
    "    Save the data for all the climate models\n",
    "    \"\"\"\n",
    "    #Get the prepared data\n",
    "    #issue with prepData function so load information beforehand\n",
    "    #lats, lons, dates, nt_yr, nr_lat, nr_lon, m = prepData(zg_file, yrst, yrend, \"JJA\", lats_arr, lons_arr, zg_str, grid_res, lat_str, lon_str)\n",
    "    lats, lons, dates = zg_file[lat_str], zg_file[lon_str], data_yr_reshaped['time']\n",
    "    yrst, yrend = int(data_yr_reshaped['time.year'].min()), int(data_yr_reshaped['time.year'].max())\n",
    "    nr_lat, nr_lon = len(lats), len(lons)\n",
    "    m = bm(projection='cyl',llcrnrlat=lats[0],urcrnrlat=lats[-1],llcrnrlon=lons[0],urcrnrlon=lons[-1],resolution='l')\n",
    "    print(f\"save_SOM data_yr_reshaped.shape = {data_yr_reshaped.shape}\")\n",
    "    #Train the SOM if not inputting an already trained SOM pattern\n",
    "    if train_input == False:\n",
    "        print(\"training\")\n",
    "        som_yr = somoclu.Somoclu(n_columns, n_rows, maptype=\"planar\",compactsupport=True,initialization=f\"{init}\", neighborhood=f\"{neigh}\", std_coeff=std)\n",
    "        som_yr.train(data_yr_reshaped,epochs=ep,radius0=rad_0,radiusN=rad_N,radiuscooling=f\"{rad_cooling}\",\n",
    "                 scale0=scale_0,scaleN=scale_N,scalecooling=f\"{scale_cooling}\")\n",
    "        bmus=som_yr.bmus\n",
    "    else:\n",
    "        #already have som_yr but need to calculate bmus\n",
    "        codebook_da = xarray.DataArray(som_yr.codebook, name = \"codebook\", dims = (\"row\", \"col\", \"latlon\"))\n",
    "        codebook_da_reshaped = codebook_da.values.reshape(n_rows*n_columns, data_yr_reshaped.shape[1])\n",
    "        codebook_da_reshaped_xr = xr.DataArray(codebook_da_reshaped, name = f\"codebook_reshaped\")\n",
    "        codebook_da_reshaped_xr = codebook_da_reshaped_xr.rename(dim_0=\"rowcol\").rename(dim_1=\"latlon_flat\")\n",
    "        bmus = SOM_fn.Identify_BMU_from_codebook(codebook_da_reshaped_xr, data_yr_reshaped, n_rows, n_columns)\n",
    "        \n",
    "    #Plot the trained SOM nodes \n",
    "    g, axes = plt.subplots(nrows=n_rows, ncols=n_columns, figsize=(10,5))\n",
    "    g.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "    #Store the frequency data in a list\n",
    "    freq_list = []\n",
    "    for i in range(n_rows): \n",
    "        for j in range(n_columns):\n",
    "            try:\n",
    "                ax = axes[i][j]\n",
    "                node = som_yr.codebook[i][j]\n",
    "            except: #doesn't work when not indexed, when one of n_rows or n_columns = 1\n",
    "                if n_rows > n_columns:\n",
    "                    ax = axes[i]\n",
    "                    node = som_yr.codebook[j]\n",
    "                else:\n",
    "                    ax = axes[i]\n",
    "                    node = som_yr.codebook[i]\n",
    "            #print(f\"node = {node}\")\n",
    "            #print(f\"node.shape = {node.shape}\")\n",
    "            node_orig = node.reshape(nr_lat,nr_lon)            \n",
    "            \n",
    "            SOM_fn.plot_field(m, node_orig, lats, lons, -330, 330, 30, ncols = n_columns, nrows = n_rows,  #for pv use -330/250, 330/250, 30/250 as levels\n",
    "                       ax=ax, grid=False, cmap=plt.get_cmap(colormap_str), fig=g, row=i, col=j)\n",
    "            #Pattern frequencies\n",
    "            if train_input == False:\n",
    "                freq = sum([1 for pat in som_yr.bmus if pat.tolist() == [j,i]])/float(len(som_yr.bmus))*100 #note the flipped indices\n",
    "            else:\n",
    "                #print(f\"pat = {[j,i]}\")\n",
    "                freq = sum([1 for pat in bmus if pat == [j,i]])/float(len(bmus))*100 #note the flipped indices\n",
    "                #print(f\"freq = {freq}\")\n",
    "            freq_list.append(freq)\n",
    "            props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "            ax.text(0.05, 0.95, str(round(freq,1))+\"%\", transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "            #ax1.ticklabel_format(style=\"plain\")      \n",
    "    suptitle=f\"zg LTDM anom {mdl} {yrst}-{yrend} JJA ({units})\"            \n",
    "    g.suptitle(f\"{suptitle}\", fontsize=10)    \n",
    "    ax.ticklabel_format(style=\"plain\")      \n",
    "    if save_SOM_str != False:\n",
    "        print(f\"save_SOM_str = {save_SOM_str}\")\n",
    "        g.savefig(save_SOM_str, bbox_inches=\"tight\", dpi = 300)\n",
    "    plt.close();\n",
    "        \n",
    "    da_xr_trend, all_occur = saveSOMTrends(som_yr, dates, n_rows, n_columns, savefig_trends, colormap_str,\n",
    "                                mult_test_method, mdl, train_input=train_input, bmus=bmus, JJA_days=JJA_days, yrst=yrst, yrend=yrend, samp=samp)#, save_SOM_trends_str=save_SOM_trends_str)\n",
    "    return da_xr_trend, all_occur, som_yr\n",
    "\n",
    "\n",
    "#Function to plot the SOM trends\n",
    "#added values to modify Gerald's function (issues with date formatting)\n",
    "def saveSOMTrends(som_yr, dates, n_rows, n_columns, savefig_trends, colormap_str, mult_test_method, mdl, train_input=False, bmus=None, JJA_days=104, \n",
    "                  yrst=1979, yrend=2019, samp=2, plot=True):\n",
    "    \"\"\"\n",
    "    Plots the trends (occurrence, persistence, max duration) of the SOM patterns generated from the GPH data. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    som_yr    : somoclu.train.Somoclu\n",
    "        The trained SOM (somoclu object)\n",
    "    seas_yr   : xarray.DataArray\n",
    "        Data array containing GPH data and information on time, latitude, longitude variables in the selected time range, season and region\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    grad_list : list \n",
    "        List of the gradients of the pattern occurrence trends computed by linear least-squares regression \n",
    "    all_occur : list \n",
    "        List of occurrences per day in the trained dataset for each SOM pattern\n",
    "    \"\"\"\n",
    "    if train_input==False:\n",
    "        #calculate the best matching unit\n",
    "        #Extract pattern data (occurence, persistence, max duration)\n",
    "        #Store each pattern data as a binary list of len(dates), i.e. [1,0,0,0,1...,1]\n",
    "        bmus = som_yr.bmus\n",
    "    \n",
    "    global all_occur\n",
    "    all_occur = [[] for i in range(max(n_rows,n_columns))]\n",
    "    for a in range(n_rows):\n",
    "        for b in range(n_columns): \n",
    "            curr_occur = []\n",
    "            for c in bmus:\n",
    "                if train_input==False:\n",
    "                    if c.tolist() == [b,a]: #### need to swap the indices here!! #b'a\n",
    "                        curr_occur.append(1) #This pattern occured on this date\n",
    "                    else:\n",
    "                        curr_occur.append(0) #This pattern didn't occur \n",
    "                else:\n",
    "                    if c == [b,a]: #### need to swap the indices here!! #b'a\n",
    "                        curr_occur.append(1) #This pattern occured on this date\n",
    "                    else:\n",
    "                        curr_occur.append(0) #This pattern didn't occur                     \n",
    "            all_occur[a].append(curr_occur)\n",
    "    #Loop through each set of circulation occurence data\n",
    "    da_arr, rownum_arr, colnum_arr = [], [], []\n",
    "    \n",
    "   \n",
    "    \n",
    "    ##### Plotting - can put in a different function\n",
    "    #####\n",
    "    if plot:\n",
    "        #Plotting axes the extracted circulation data\n",
    "        if n_columns == 1:\n",
    "            f, axes1 = plt.subplots(nrows=n_rows, ncols=n_columns+1, figsize=(10,10))\n",
    "        elif n_rows == 1:\n",
    "            f, axes1 = plt.subplots(nrows=n_rows+1, ncols=n_columns, figsize=(10,10))\n",
    "        else:\n",
    "            f, axes1 = plt.subplots(nrows=n_rows, ncols=n_columns, figsize=(10,10))\n",
    "        f.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "    test_num = 8 #number of p value tests in family of hypotheses (occ, persis, max_dur and event_no * 2)\n",
    "    #pvalue and gradient matrices for each node\n",
    "    pval_mat, grad_mat = np.zeros((n_rows,n_columns,test_num)), np.zeros((n_rows,n_columns,test_num))    \n",
    "    grad_list = []\n",
    "    for row in range(n_rows):  \n",
    "        for col in range(n_columns):\n",
    "            #Need some exception handling for rare cases where any of the patterns doesnt occur in a year\n",
    "            #NOTE the swapped indices [col][row] here! Doulbe check with Joy's code, see if node number can be confirmed\n",
    "            #print(f\"all_occur[row][col] = {all_occur[row][col]}\")\n",
    "            #all_occur[row][col] is the relevant matrix for investigating case studies\n",
    "            cum_data = pd.Series(np.array(all_occur[row][col]), index=dates.values)\n",
    "            #print(f\"cum_data = {cum_data}\")\n",
    "            #to generate the years in the dataset, since cum_data.index.year has issues\n",
    "            #print(f\"JJA_days = {JJA_days}\")       \n",
    "            #print(f\"cum_data.shape = {cum_data.shape}\")\n",
    "            years_num=int(cum_data.shape[0]/JJA_days)\n",
    "            #print(f\"cum_data.shape[0]/JJA_days = {cum_data.shape[0]}/{JJA_days} = {cum_data.shape[0]/JJA_days}\")\n",
    "            #print(f\"years_num = {years_num}\")\n",
    "            years_zeros = np.zeros((years_num*JJA_days))\n",
    "            if type(yrst) == int or type(yrst) == float:\n",
    "                arr_gen = np.array([years_zeros[JJA_days*i:JJA_days*(i+1)]+i+yrst for i in range(years_num)\n",
    "                               ]).reshape(years_num*JJA_days)\n",
    "            else: #yrst an array\n",
    "                print(\"yrst an array\")\n",
    "                arr_gen = np.array([years_zeros[JJA_days*i:JJA_days*(i+1)]+i+int(yrst.values) for i in range(years_num)\n",
    "                               ]).reshape(years_num*JJA_days)\n",
    "            #print(f\"len(arr_gen) = {len(arr_gen)}\")\n",
    "            sort_to_year = cum_data.groupby(arr_gen).apply(list)\n",
    "            year = np.array(sort_to_year.keys().tolist()) #[1979, 1980,...]\n",
    "            occ = [sum(d) for d in sort_to_year]  #[25,40,...]\n",
    "            # Count streaks \n",
    "            streaks = [[sum(1 for i in g) for k,g in groupby(x) if k == 1] for x in sort_to_year]\n",
    "            streak_count = [[(k, sum(1 for i in g)) for k,g in groupby(sorted(x)) ] for x in streaks]\n",
    "            \n",
    "            #Persistence (if statement to avoid division by zero )\n",
    "            persis = [ sum([x[0]*x[1] for x in year])/sum([x[1] for x in year]) if sum([x[1] for x in year]) != 0 else 0 for year in streak_count ]\n",
    "            #Max Duration \n",
    "            max_dur = [ year[-1][0] if year != [] else 0 for year in streak_count]\n",
    "            ##want to store occ, persis, max_dur and ev_no in a xarray Dataset/DataArray to save, with the time file showing the years\n",
    "            ##need to store this for each node (36 different 1d arrays for each model, plus the timestamp)\n",
    "\n",
    "            def len_iter(items):\n",
    "                return sum(1 for _ in items)            \n",
    "            \n",
    "            def consecutive_one_len(data):\n",
    "                return len(list(len_iter(run) for val, run in groupby(data) if val))            \n",
    "            event_no = [consecutive_one_len(d) for d in sort_to_year] \n",
    "            \n",
    "            store = [occ, persis, max_dur, event_no]\n",
    "            \n",
    "            da = xarray.DataArray(store, dims = ('SOM_trend_metrics', \"year\"))\n",
    "            da['year'] = year\n",
    "            da['SOM_trend_metrics'] = ['occ', 'persis', 'max_dur', 'event_no']\n",
    "            da_arr.append(da)\n",
    "            #store the DataArray and the accompanying row and column number of the SOM pattern            \n",
    "            rownum_arr.append(row)\n",
    "            colnum_arr.append(col)\n",
    "            \n",
    "            if plot:\n",
    "                def len_iter(items):\n",
    "                    return sum(1 for _ in items)            \n",
    "\n",
    "                def consecutive_one_len(data):\n",
    "                    return len(list(len_iter(run) for val, run in groupby(data) if val))            \n",
    "                event_no = [consecutive_one_len(d) for d in sort_to_year]      \n",
    "                #event_no = [sum(d) for d in sort_to_year]        \n",
    "                #np.ones((len(sort_to_year)))*sum(sort_to_year)\n",
    "                #Fitting via Linear Least Squares Regression (With Serial Correlation)\n",
    "                def fit(m,x,c):  #Simple linear function\n",
    "                    return m*x + c\n",
    "\n",
    "                #Occurrence \n",
    "                m0, c0, r0, p0, err0 = scipy.stats.linregress(year,occ)\n",
    "                m1, c1, r1, p1, err1 = scipy.stats.linregress(year[:],occ[:])\n",
    "                fit_occ = [fit(m0,x,c0) for x in year]\n",
    "                fit_occ1 = [fit(m1,x,c1) for x in year[:]]\n",
    "                grad_list.append(m0)\n",
    "\n",
    "                #Persistence\n",
    "                m2, c2, r2, p2, err2 = scipy.stats.linregress(year,persis)\n",
    "                m3, c3, r3, p3, err3 = scipy.stats.linregress(year[:],persis[:])\n",
    "                fit_per = [fit(m2,x,c2) for x in year]\n",
    "                fit_per1 = [fit(m3,x,c3) for x in year[:]]\n",
    "\n",
    "                #Max duration\n",
    "                m4, c4, r4, p4, err4 = scipy.stats.linregress(year,max_dur)\n",
    "                m5, c5, r5, p5, err5 = scipy.stats.linregress(year[:],max_dur[:])\n",
    "                fit_dur = [fit(m4,x,c4) for x in year]\n",
    "                fit_dur1 = [fit(m5,x,c5) for x in year[:]]\n",
    "\n",
    "                #Event number\n",
    "                m6, c6, r6, p6, err6 = scipy.stats.linregress(year,event_no)\n",
    "                m7, c7, r7, p7, err7 = scipy.stats.linregress(year[:],event_no[:])\n",
    "                fit_evno = [fit(m6,x,c6) for x in year]\n",
    "                fit_evno1 = [fit(m7,x,c7) for x in year[:]]\n",
    "                \n",
    "                #Plot results\n",
    "                row, col = int(row), int(col)\n",
    "                occ, persis, max_dur, event_no = np.array(occ), np.array(persis), np.array(max_dur), np.array(event_no)\n",
    "                \n",
    "                axes1[row][col].scatter(year, occ, c='k', s=3, label=\"Occurrences\") #plot occurrences vs years\n",
    "                axes1[row][col].plot(year, fit_occ, c='k')\n",
    "                axes1[row][col].plot(year[:], fit_occ1, '--', c='k')\n",
    "\n",
    "                axes1[row][col].scatter(year, persis, c='b', s=3, label=\"Persistence\") #plot persistence vs years\n",
    "                axes1[row][col].plot(year, fit_per, c='b')\n",
    "                axes1[row][col].plot(year[:], fit_per1, '--', c='b')\n",
    "\n",
    "                axes1[row][col].scatter(year, max_dur, c='r', s=3, label=\"Max Duration\") #plot max duration vs years\n",
    "                axes1[row][col].plot(year, fit_dur, c='r')\n",
    "                axes1[row][col].plot(year[:], fit_dur1, '--', c='r')\n",
    "\n",
    "                axes1[row][col].scatter(year, event_no, c=(0.5,0.5,0.5), s=3, label=\"Event no\") #plot event number vs years\n",
    "                axes1[row][col].plot(year, fit_evno, c=(0.5,0.5,0.5))\n",
    "                axes1[row][col].plot(year[:], fit_evno1, '--', c=(0.5,0.5,0.5))         \n",
    "\n",
    "                if n_rows*n_columns > 5:\n",
    "                    font_size_text = 8\n",
    "                    font_size_title = 9 \n",
    "                else:\n",
    "                    font_size_text = 11\n",
    "                    font_size_title = 12                  \n",
    "                font_size_suptitle = 14\n",
    "                #corrected p values\n",
    "                (pval_occ, pval_occ_samp, pval_persis, pval_persis_samp, \n",
    "                 pval_max_dur, pval_max_dur_samp, pval_event_no, pval_event_no_samp) = (SOM_fn.lmtrendtest(year, occ), SOM_fn.lmtrendtest(year[:], occ[:]),\n",
    "                                                                                        SOM_fn.lmtrendtest(year, persis), SOM_fn.lmtrendtest(year[:], persis[:]),\n",
    "                                                                                        SOM_fn.lmtrendtest(year, max_dur), SOM_fn.lmtrendtest(year[:], max_dur[:]),\n",
    "                                                                                        SOM_fn.lmtrendtest(year, event_no), SOM_fn.lmtrendtest(year[:], event_no[:]))\n",
    "                #store the calculated p values in a matrix\n",
    "                pval_mat[row,col,:] = [pval_occ, pval_occ_samp, pval_persis, pval_persis_samp, pval_max_dur, pval_max_dur_samp, pval_event_no, pval_event_no_samp]\n",
    "                grad_mat[row,col,:] = [m0,m1,m2,m3,m4,m5,m6,m7]\n",
    "    \n",
    "    if plot:\n",
    "        if mult_test_method == \"none\":\n",
    "            print(\"No multiple hypothesis correction applied\")\n",
    "        elif mult_test_method == \"k-FWER\":    \n",
    "            #test for the k-familywise error rate using the Bonferroni correction\n",
    "            pval_arr = SOM_fn.Bonferroni_kFWER(pval_mat[:,:,:].flatten(), k = 20)\n",
    "            pval_mat = pval_arr.reshape((n_rows,n_columns,test_num)) \n",
    "        else:\n",
    "            pval_arr = multipletests(pval_mat[:,:,:].flatten(), alpha=0.05, method=mult_test_method, is_sorted=False, returnsorted=False)[1]  \n",
    "            pval_mat = pval_arr.reshape((n_rows,n_columns,test_num)) \n",
    "\n",
    "        for row in range(n_rows):  \n",
    "            for col in range(n_columns):\n",
    "                m0,m1,m2,m3,m4,m5,m6,m7 = grad_mat[row,col,:]\n",
    "                p0,p1,p2,p3,p4,p5,p6,p7 = pval_mat[row,col,:]\n",
    "                #Legend\n",
    "                #calculate the corrected p values and create the strings to reduce the bold text\n",
    "                m0_str, m1_str, m2_str, m3_str, m4_str, m5_str, m6_str, m7_str = (SOM_fn.pval_str(m0, p0), SOM_fn.pval_str(m1, p1), \n",
    "                                                                  SOM_fn.pval_str(m2, p2), SOM_fn.pval_str(m3, p3), \n",
    "                                                                  SOM_fn.pval_str(m4, p4), SOM_fn.pval_str(m5, p5),\n",
    "                                                                  SOM_fn.pval_str(m6, p6), SOM_fn.pval_str(m7, p7))\n",
    "                axes1[row][col].text(0.16, 0.99, \"Occurrence\", transform=axes1[row][col].transAxes, fontsize=font_size_title, verticalalignment='top', horizontalalignment='center')\n",
    "                axes1[row][col].text(0.16, 0.93, m0_str,\n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center')\n",
    "                axes1[row][col].text(0.16, 0.87, m1_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center')\n",
    "\n",
    "                axes1[row][col].text(0.49, 0.99, \"Persistence\", transform=axes1[row][col].transAxes, fontsize=font_size_title, verticalalignment='top',horizontalalignment='center', color='b')\n",
    "                axes1[row][col].text(0.49, 0.93, m2_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center', color='b')\n",
    "                axes1[row][col].text(0.49, 0.87, m3_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center', color='b')\n",
    "\n",
    "                axes1[row][col].text(0.83, 0.99, \"Max duration\", transform=axes1[row][col].transAxes, fontsize=font_size_title, verticalalignment='top', horizontalalignment='center', color='r')\n",
    "                axes1[row][col].text(0.83, 0.93, m4_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center', color='r')\n",
    "                axes1[row][col].text(0.83, 0.87, m5_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center', color='r')      \n",
    "\n",
    "                axes1[row][col].text(0.16, 0.82, f\"Event no\", transform=axes1[row][col].transAxes, fontsize=font_size_title, verticalalignment='top', horizontalalignment='center', color=(0.5,0.5,0.5))\n",
    "                axes1[row][col].text(0.16, 0.76, m6_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center', color=(0.5,0.5,0.5))\n",
    "                axes1[row][col].text(0.16, 0.70, m7_str, \n",
    "                                     transform=axes1[row][col].transAxes, fontsize=font_size_text, verticalalignment='top', horizontalalignment='center', color=(0.5,0.5,0.5))               \n",
    "\n",
    "                axes1[row][col].set_ylim((0,55))            \n",
    "            f.suptitle(f'Time series of circulation trends \\n {mdl} {yrst}-{yrend}', fontsize=14)\n",
    "        f.savefig(savefig_trends, bbox_inches=\"tight\", dpi=300) \n",
    "        plt.close();\n",
    "    #####        \n",
    "    #####        \n",
    "            \n",
    "    #concatenate the array\n",
    "    da_xr = xarray.concat(da_arr, dim = (\"node\"))\n",
    "    #add a new coordinates to specify the row and column number for each layer\n",
    "    da_xr = da_xr.assign_coords(\n",
    "        rownum=('node', rownum_arr))\n",
    "    da_xr = da_xr.assign_coords(\n",
    "        colnum=('node', colnum_arr))           \n",
    "            \n",
    "    return da_xr, all_occur\n",
    "\n",
    "\n",
    "#file_zg_str, n_rows, n_columns, yrnum_test, yrnum_train_red, num_yrs_train\n",
    "def SOM_calc_samp(file_zg_str, n_rows, n_columns, yrnum_test, yrnum_train_red, num_yrs_train):\n",
    "    \"\"\"\n",
    "    Calculate and save the trained arrangement of SOM nodes for a set of subsamples of the data for the purposes of cross-validation \n",
    "    \"\"\"\n",
    "    file_zg_tot = xarray.open_dataset(file_zg_str).squeeze()\n",
    "    \n",
    "    yrst, yrend = int(file_zg_tot['time.year'].min()), int(file_zg_tot['time.year'].max())\n",
    "    shift_years = 0\n",
    "    if \"era5\" in file_zg_str:\n",
    "        shift_years = 1 # shift the starting year by 1 to skip cross-validation on 1979\n",
    "    yrst_train_arr = range(1960,2060,10)#[yrst+shift_years+i*yrnum_test for i in range(int((yrend - yrst)/yrnum_test))]   \n",
    "    \n",
    "    k = 10#int((yrend - yrst)/yrnum_test)\n",
    "    #print(f\"{k}-fold cv\")    \n",
    "    if \"rel_vort\" in file_zg_str:\n",
    "        zg_str = \"rel_vort\"\n",
    "        units = \"s$^{-1}$\"\n",
    "        if \"era5\" in file_zg_str:\n",
    "            data_yr_reshaped_str = \"/rds/general/project/carl_phd/live/carl/data/era5/day/rel_vort/500xi_era5_day_1979-2019_1x1_EUR_LTDManom_reshaped.nc\"\n",
    "        else:\n",
    "            data_yr_reshaped_str = (\"/rds/general/project/carl_phd/live/carl/data/cmip6/UKESM1-0-LL/piControl/day/r1i1p1f2/rel_vort/\"\n",
    "            \"500xi_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_1960-2060_r180x91_latcorr_EUR_LTDManom_JJAextd_reshaped.nc\")\n",
    "            #(\"/rds/general/project/carl_phd/live/carl/data/cmip6/UKESM1-0-LL/piControl/day/r1i1p1f2/rel_vort/\"\n",
    "            #\"500xi_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_1960-2060_r180x91_latcorr_EUR_LTDManom_JJAextd_reshaped.nc\")\n",
    "    pt_str = \"_350pt\"\n",
    "    \n",
    "    if \"vpv\" in file_zg_str:\n",
    "        zg_str = \"VPV\"\n",
    "        units = \"PVU\"\n",
    "        data_yr_reshaped_str = \"/rds/general/project/nowack_graven/live/carl/pv_era5/vpv_1x1_day_150-500hPa_hires_1979-2019_LTDManom_JJAextd_EUR_reshaped.nc\"\n",
    "    if \"pv_330pt\" in file_zg_str:\n",
    "        zg_str = \"ipv_330pt\"\n",
    "        units = \"PVU\"\n",
    "        data_yr_reshaped_str = \"/rds/general/project/carl_phd/live/carl/data/era5/day/pv/isentropes/pv_330pt_era5_1979-2019_1x1_EUR_daymean_invlat_LTDManom_JJAextd_reshaped.nc\"\n",
    "    if \"pv_350pt\" in file_zg_str:\n",
    "        zg_str = \"pv_350pt\"\n",
    "        units = \"PVU\"\n",
    "        data_yr_reshaped_str = \"/rds/general/user/cmt3718/home/pv_350pt_era5_1979-2019_1x1_tot_3hr_daymean_ydayavg_LTDManom_invlat_JJAextd_reshaped.nc\"\n",
    "    if \"psl\" in file_zg_str:\n",
    "        zg_str = \"psl\"\n",
    "        units = \"Pa\"\n",
    "        data_yr_reshaped_str = (\"/rds/general/user/cmt3718/home/data/cmip6/UKESM1-0-LL/piControl/r1i1p1f2/psl/\"\n",
    " \"psl_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_19600101-20601230_r180x91_LTDManom_EUR2_JJAextd_dtrnd_reshaped.nc\")     \n",
    "    if \"msl\" in file_zg_str:\n",
    "        zg_str = \"msl\"\n",
    "        units = \"Pa\"\n",
    "        data_yr_reshaped_str = f\"/rds/general/project/nowack_graven/live/carl/era5/mean_sea_level_pressure/mslp_ERA5_{yrst}-{yrend}_EUR_JJAextd_LTDMdaymean_anom_reshaped2.nc\"\n",
    "    if \"zg\" in file_zg_str:\n",
    "        zg_str = \"z\"\n",
    "        units = \"hPa\"\n",
    "        data_yr_reshaped_str = \"/rds/general/project/carl_phd/live/carl/data/era5/day/zg/LTDM/z_timedtrnd_ERA5_1979-2019_EUR_JJAextd_LTDMdaymean_anom_sort_reshaped.nc\"\n",
    "        #(\"/rds/general/project/carl_phd/live/carl/data/era5/day/zg/LTDM/500zg_1x1_1979-2019_JJAextd_LTDManom_nolp_EurAR5_timedtrnd_reshaped.nc\")\n",
    "        #f\"/rds/general/project/carl_phd/live/carl/data/era5/day/zg/LTDM/z_timedtrnd_ERA5_{yrst}-{yrend}_EUR_JJAextd2_LTDMdaymean_anom_reshaped.nc\"\n",
    "    if \"UKESM\" in file_zg_str:\n",
    "        if \"rel_vort\" in file_zg_str:\n",
    "            #data_yr_reshaped_str = \"/rds/general/project/carl_phd/live/carl/data/cmip6/UKESM1-0-LL/piControl/day/r1i1p1f2/rel_vort/500xi_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_1960-2060_r180x91_latcorr_EUR_LTDManom_JJAextd_reshaped.nc\"\n",
    "            #print(data_yr_reshaped_str)\n",
    "           ## print(xr.open_dataset(data_yr_reshaped_str))\n",
    "            data_yr_reshaped = xr.open_dataset(data_yr_reshaped_str)['UKESM1-0-LL_rel_vort_reshaped']\n",
    "        if \"zg\" in file_zg_str:\n",
    "            zg_str = \"zg\"\n",
    "            data_yr_reshaped_str = (\"/rds/general/user/cmt3718/home/data/cmip6/UKESM1-0-LL/piControl/r1i1p1f2/zg/\"\n",
    "                \"500zg_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_19600101-20601230_r180x91_LTDManom_EUR_JJAextd_dtrnd_reshaped.nc\")\n",
    "            data_yr_reshaped = xr.open_dataset(data_yr_reshaped_str)['data_yr_reshaped']\n",
    "        if \"psl\" in file_zg_str:\n",
    "            zg_str = \"psl\"\n",
    "            data_yr_reshaped_str = (\"/rds/general/user/cmt3718/home/data/cmip6/UKESM1-0-LL/piControl/r1i1p1f2/psl/\"\n",
    "                \"psl_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_19600101-20601230_r180x91_LTDManom_EUR_JJAextd_dtrnd_reshaped.nc\")\n",
    "            data_yr_reshaped = xr.open_dataset(data_yr_reshaped_str)['data_yr_reshaped']\n",
    "    if \"era5\" in data_yr_reshaped_str:\n",
    "        if \"pv_350pt\" in file_zg_str:\n",
    "            data_yr_reshaped = xr.open_dataset(data_yr_reshaped_str)[f'era5_ipv_350K_reshaped']\n",
    "        else:\n",
    "            data_yr_reshaped = xr.open_dataset(data_yr_reshaped_str)[f'era5_{zg_str}_reshaped']\n",
    "    file_zg_tot = file_zg_tot[zg_str.split(pt_str)[0]]\n",
    "    if \"rel_vort\" not in file_zg_str and \"UKESM\" not in file_zg_str:\n",
    "        file_zg_tot = sel_JJA_extd(file_zg_tot)\n",
    "\n",
    "    lat_str, lon_str = \"latitude\", \"longitude\"\n",
    "    if \"era5\" in file_zg_str:\n",
    "        mdl, ens = \"era5\", \"reanal\"\n",
    "        mdl_ens_str = f\"{mdl}_{ens}\"\n",
    "        mip = \"reanal\"\n",
    "    if \"UK\" in file_zg_str:\n",
    "        mdl, ens = \"UKESM1-0-LL\", \"r1i1p1f2\"\n",
    "        mdl_ens_str = f\"{mdl}_{ens}\"\n",
    "        mip = \"cmip6\"\n",
    "        lat_str, lon_str = \"lat\", \"lon\"\n",
    "    lats, lons = np.arange(30,77), np.arange(-10,41)\n",
    "    #need to adjust the longitude coordinate if it runs from 0 - 360 E instead of -180 to +180 E\n",
    "    file_zg_tot=SOM_fn.da_lon_adj(file_zg_tot)\n",
    "    if \"UKESM\" in file_zg_str:\n",
    "        file_zg_tot = file_zg_tot.sel(time = np.isin(file_zg_tot['time.dayofyear'], np.arange(147,245)))\n",
    "    else:\n",
    "        JJA_extd_daymonth_xr = xr.open_dataset(\"/rds/general/project/nowack_graven/live/carl/era5/day_month_1979-2019_JJAextd.nc\")['JJA_extd']\n",
    "        #zg_file['day_month'] = xr.open_dataset(\"/rds/general/project/nowack_graven/live/carl/era5/day_month_1979-2019_nolp.nc\")['day_month']\n",
    "        day_month = xr.open_dataset(\"/rds/general/project/nowack_graven/live/carl/era5/day_month_1979-2019_nolp.nc\")['day_month']\n",
    "        file_zg_tot = file_zg_tot.sel(latitude = np.isin(file_zg_tot['latitude'], lats), \n",
    "                                  longitude = np.isin(file_zg_tot['longitude'], lons))\n",
    "        #if \"msl\" in file_zg_str:\n",
    "        #    file_zg_tot = file_zg_tot.sel(time = np.isin(day_month, JJA_extd_daymonth_xr))\n",
    "        #.sel(time = np.isin(file_zg_tot['time.year'], np.arange(yrst_train, yrst_train+yrnum_train+1), invert=True))[zg_str]\n",
    "    num_days, num_lats, num_lons = file_zg_tot.shape\n",
    "\n",
    "    vmin, vmax, step = -15, 15, 1.5\n",
    "    init, neigh, std, ep, rad_0, rad_N, rad_cooling, scale_0, scale_N, scale_cooling = \"pca\", \"gaussian\", 0.5, 50, 1, 0, \"linear\", 0.1, 0.01, \"exponential\"\n",
    "    region, season = \"Europe\", \"JJA_extd\"\n",
    "    domain=\"EUR\"\n",
    "    samp =2 #int((yrst_train_arr[1]-yrst_train_arr[0])/2)\n",
    "    colormap_str = \"seismic\"\n",
    "    suptitle=f\"zg LTDM anom {mdl} {yrst}-{yrend} JJA extd ({units})\"\n",
    "    #all cover different variations on the mltiple hypothesis test applied in Horton et al 2015\n",
    "    mult_test_method = \"fdr_bh\"#\"k-FWER\"#\"none\"#\"fdr_bh\"\n",
    "\n",
    "    #cross-validation training period\n",
    "    for yrst_train in yrst_train_arr[:]:\n",
    "        print(\" --------------------- \\n \")\n",
    "        print(f\"train period {yrst_train}-{yrst_train+yrnum_test}\")\n",
    "        #print(f\"file_zg_tot = {file_zg_tot}\")\n",
    "        #print(f\"file_zg_str = {file_zg_str}\")\n",
    "        \n",
    "        \n",
    "        file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                            np.arange(yrst_train, yrst_train+yrnum_train_red+yrnum_test), invert=True))\n",
    "        file_zg_tot_cv = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                            np.arange(yrst_train, yrst_train+yrnum_test), invert=False))             \n",
    "\n",
    "        data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                    np.arange(yrst_train, yrst_train+yrnum_train_red+yrnum_test), invert=True))\n",
    "        data_yr_reshaped_cv = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                    np.arange(yrst_train, yrst_train+yrnum_test), invert=False))                \n",
    "        \n",
    "        if yrst_train == 2050:\n",
    "            #remove backwards from 2016\n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train-yrnum_train_red, yrst_train+yrnum_test), invert=True))\n",
    "            file_zg_tot_cv = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train, yrst_train+yrnum_test), invert=False))             \n",
    "\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train-yrnum_train_red, yrst_train+yrnum_test), invert=True))\n",
    "            data_yr_reshaped_cv = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train, yrst_train+yrnum_test), invert=False)) \n",
    "            \n",
    "        if yrst_train-yrnum_train_red > 1960:\n",
    "            #remove forwards from 1984\n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train, yrst_train+yrnum_train_red+yrnum_test), invert=True))\n",
    "            file_zg_tot_cv = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train, yrst_train+yrnum_test), invert=False))             \n",
    "\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train, yrst_train+yrnum_train_red+yrnum_test), invert=True))\n",
    "            data_yr_reshaped_cv = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train, yrst_train+yrnum_test), invert=False))            \n",
    "        \n",
    "        if yrst_train == 1960:\n",
    "            print(f\"yrst_train == 1980\")\n",
    "            #remove forwards from 1984\n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train, yrst_train+yrnum_train_red+yrnum_test), invert=True))\n",
    "            file_zg_tot_cv = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train, yrst_train+yrnum_test), invert=False))             \n",
    "\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train, yrst_train+yrnum_train_red+yrnum_test), invert=True))\n",
    "            data_yr_reshaped_cv = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train, yrst_train+yrnum_test), invert=False))        \n",
    "        \n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        #for 1984-1987 and yrnum_train_red > 31\n",
    "        yrnum_test = 10\n",
    "        if yrst_train+yrnum_train_red+yrnum_test > 2060:\n",
    "            max_yrs_train = 91\n",
    "            num_years_to_train = max_yrs_train-yrnum_train_red\n",
    "            print(f\"num_years_to_train = {num_years_to_train}\")\n",
    "            #if you need to remove forwards and backwards\n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst, yrst+num_years_to_train), invert=False))\n",
    "            file_zg_tot_cv = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train, yrst_train+yrnum_test), invert=False))             \n",
    "\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst, yrst+num_years_to_train), invert=False))\n",
    "            data_yr_reshaped_cv = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train, yrst_train+yrnum_test), invert=False))     \n",
    "            \n",
    "            \n",
    "        if yrst_train-num_yrs_train < yrst:\n",
    "            #can exclusively use years before start of test period for training\n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst, yrst_train-num_yrs_train), invert=False))\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst, yrst_train-num_yrs_train), invert=False))\n",
    "        elif yrst_train+yrnum_test+num_yrs_train < yrend:\n",
    "            #can exclusively use years after end of test period for training            \n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train+yrnum_test, yrst_train+yrnum_test+num_yrs_train), invert=False))\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train+yrnum_test, yrst_train+yrnum_test+num_yrs_train), invert=False))                \n",
    "        else:\n",
    "            #need to use years from both before and after the training period\n",
    "            file_zg_tot_train_after = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst_train+yrnum_test, yrst_train+yrnum_test+num_yrs_train), invert=False))\n",
    "            data_yr_reshaped_train_after = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                        np.arange(yrst_train+yrnum_test, yrst_train+yrnum_test+num_yrs_train), invert=False))   \n",
    "            num_yrs_training_after = len(np.unique(file_zg_tot_train_after['time.year'])) \n",
    "            print(f\"num_yrs_training_after = {num_yrs_training_after}\")\n",
    "            print(f\"years to add = {num_yrs_train-num_yrs_training_after}\")\n",
    "            \n",
    "            yrs_to_add_before = num_yrs_train-num_yrs_training_after\n",
    "            \n",
    "            file_zg_tot_train = file_zg_tot.sel(time = np.isin(file_zg_tot['time.year'], \n",
    "                                                np.arange(yrst+yrs_to_add_before, yrst_train+yrnum_test)#[1999,2000,2001,2002,2003,2004]\n",
    "                                                               , invert=True))\n",
    "            data_yr_reshaped_train = data_yr_reshaped.sel(time = np.isin(data_yr_reshaped['time.year'], \n",
    "                                                       np.arange(yrst+yrs_to_add_before, yrst_train+yrnum_test), invert=True))               \n",
    "        \n",
    "        \n",
    "        num_yrs_training = len(np.unique(file_zg_tot_train['time.year'])) \n",
    "        print(f\"num_yrs_training = {num_yrs_training}\")\n",
    "        print(f\"data_yr_reshaped_train = {np.unique(data_yr_reshaped_train['time.year'])}\")\n",
    "        print(f\"data_yr_reshaped_cv = {np.unique(data_yr_reshaped_cv['time.year'])}\") \n",
    "        print(f\"file_zg_tot_train = {np.unique(file_zg_tot_train['time.year'])}\")\n",
    "        print(f\"file_zg_tot_cv = {np.unique(file_zg_tot_cv['time.year'])}\")        \n",
    "        yrend_cv = yrst_train+yrnum_test-1\n",
    "        if \"UKESM\" in file_zg_str:\n",
    "            #/rds/general/user/cmt3718/home/data/cmip6/SOM/trends/UK-ESM1-0-LL_piControl/zg/crossval/10-fold\n",
    "            #/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/zg/crossval/5-fold/\n",
    "            savefig_SOM = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/{zg_str}/crossval/{k}-fold/training_yrs/plots/\"\n",
    "                   f\"SOM_fig_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom_{num_yrs_training}yrstrain.png\")\n",
    "            savefig_trends = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/{zg_str}/crossval/{k}-fold/training_yrs/plots/\"\n",
    "                   f\"SOMtrends_fig_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom_{num_yrs_training}yrstrain.png\")\n",
    "            SOM_trend_str_train = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_train_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "            SOM_data_occ_str_train = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_data_occur_train_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "            SOM_trend_str_cv = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_cv_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "            SOM_data_occ_str_cv = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_data_occur_cv_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "\n",
    "        elif \"era5\" in file_zg_str:\n",
    "            savefig_SOM = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/{zg_str}/crossval/{k}-fold/training_yrs/plots/\"\n",
    "                   f\"SOM_fig_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.png\")\n",
    "            savefig_trends = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/{zg_str}/crossval/{k}-fold/training_yrs/plots/\"\n",
    "                   f\"SOMtrends_fig_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.png\")\n",
    "            SOM_trend_str_train = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_train_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "            SOM_data_occ_str_train = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_data_occur_train_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_not{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "            SOM_trend_str_cv = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_cv_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "            SOM_data_occ_str_cv = (f\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/{zg_str}/crossval/{k}-fold/training_yrs/\"\n",
    "                   f\"SOM_data_occur_cv_{mdl_ens_str}_{n_rows}x{n_columns}_{domain}_{int(yrst_train)}-{int(yrend_cv)}_{season}_{zg_str}_LTDManom{num_yrs_training}yrstrain.nc\")\n",
    "        else:\n",
    "            print(\"not UKESM or era5 - cannot define save directories\")\n",
    "            return\n",
    "        print(f\"saving training in {SOM_trend_str_train}\")\n",
    "        print(f\"saving cv in {SOM_trend_str_cv}\")  \n",
    "     \n",
    "        JJA_days = int(len(np.unique(file_zg_tot['time.dayofyear'])))\n",
    "        if \"era5\" in file_zg_str and \"_z_\" in file_zg_str:# and \"pv_350pt\" not in file_zg_str and \"vort\" not in file_zg_str:\n",
    "            JJA_days = 100\n",
    "            #JJA_days = JJA_days-1 #where there are leap years, need to remove from JJA_days since dayofyear will reflec the different leap year\n",
    "        JJA_days = 98\n",
    "        #print(f\"JJA_days = {JJA_days}\")\n",
    "        #load the training dataset\n",
    "        da_xr_trend_train, all_occur_train, som_yr_train = save_SOM_data(file_zg_tot_train, yrst, yrend, \n",
    "                    season, region, init, neigh, std, ep, rad_0, rad_N, rad_cooling, scale_0, scale_N, scale_cooling,\n",
    "                    savefig_SOM, savefig_trends, n_rows, n_columns, samp, zg_str, colormap_str, suptitle, mult_test_method, \n",
    "                        data_yr_reshaped_train, vmin, vmax, step, lat_str, lon_str, units, mdl_ens_str, train_input = False, JJA_days=JJA_days, save_SOM_str=savefig_SOM)\n",
    "\n",
    "        #print(\"use trained SOM to calculate cv dataset\")\n",
    "        #using the trained SOM, calculate the \n",
    "        da_xr_trend_cv, all_occur_cv, som_yr_train = save_SOM_data(file_zg_tot_cv, yrst, yrend, \n",
    "                    season, region, init, neigh, std, ep, rad_0, rad_N, rad_cooling, scale_0, scale_N, scale_cooling,\n",
    "                    savefig_SOM, savefig_trends, n_rows, n_columns, samp, zg_str, colormap_str, suptitle, mult_test_method, \n",
    "                        data_yr_reshaped_cv, vmin, vmax, step, lat_str, lon_str, units, mdl_ens_str, train_input = True, som_yr = som_yr_train, JJA_days=JJA_days)\n",
    "\n",
    "\n",
    "        da_xr_trend_train.to_netcdf(SOM_trend_str_train)\n",
    "        da_train=xarray.DataArray(all_occur_train, name = \"SOM_data\", dims = (\"row\", \"col\", \"time\"))\n",
    "        da_train['time']=file_zg_tot_train['time']\n",
    "        da_train.to_netcdf(SOM_data_occ_str_train)\n",
    "      \n",
    "        da_xr_trend_cv.to_netcdf(SOM_trend_str_cv)\n",
    "        da_cv=xarray.DataArray(all_occur_cv, name = \"SOM_data\", dims = (\"row\", \"col\", \"time\"))\n",
    "        da_cv['time']=file_zg_tot_cv['time']\n",
    "        da_cv.to_netcdf(SOM_data_occ_str_cv)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test what years are missing from the SOM CV data which need to be run\n",
    "# dir_str=\"/rds/general/project/nowack_graven/live/carl_som_index/data/era5/z/crossval/10-fold/training_yrs/\"\n",
    "\n",
    "\n",
    "# year_str_arr = [\"1980-1983\",\"1984-1987\",\"1988-1991\",\"1992-1995\",\"1996-1999\",\"2000-2003\",\"2004-2007\",\"2008-2011\",\"2012-2015\",\"2016-2019\"]\n",
    "\n",
    "\n",
    "# for year_str in year_str_arr:\n",
    "    \n",
    "#     file_list=sorted(glob.glob(f\"{dir_str}*SOM_train_era5_reanal_5x4_EUR_not{year_str}_JJA_extd_z_LTDManom*\"))#3yrstrain.nc\"))\n",
    "#     years_done = sorted([int(file.split(\"LTDManom\")[1].split(\"yrstrain\")[0]) for file in file_list])\n",
    "#     if len(file_list) != 37:\n",
    "#         print(year_str)\n",
    "#         print(years_done)\n",
    "#         print(len(file_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------- \n",
      " \n",
      "train period 1960-1970\n",
      "yrst_train == 1980\n",
      "num_yrs_training = 42\n",
      "data_yr_reshaped_train = [2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032\n",
      " 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046\n",
      " 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060]\n",
      "data_yr_reshaped_cv = [1960 1961 1962 1963 1964 1965 1966 1967 1968 1969]\n",
      "file_zg_tot_train = [2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032\n",
      " 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046\n",
      " 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060]\n",
      "file_zg_tot_cv = [1960 1961 1962 1963 1964 1965 1966 1967 1968 1969]\n",
      "saving training in /rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/zg/crossval/10-fold/training_yrs/SOM_train_UKESM1-0-LL_r1i1p1f2_5x4_EUR_not1960-1969_JJA_extd_zg_LTDManom42yrstrain.nc\n",
      "saving cv in /rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/zg/crossval/10-fold/training_yrs/SOM_cv_UKESM1-0-LL_r1i1p1f2_5x4_EUR_1960-1969_JJA_extd_zg_LTDManom42yrstrain.nc\n",
      "save_SOM data_yr_reshaped.shape = (4116, 624)\n",
      "training\n",
      "save_SOM_str = /rds/general/project/nowack_graven/live/carl_som_index/data/UKESM1-0-LL_piControl/zg/crossval/10-fold/training_yrs/plots/SOM_fig_UKESM1-0-LL_r1i1p1f2_5x4_EUR_not1960-1969_JJA_extd_zg_LTDManom_42yrstrain.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e81899fd498c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrowcols_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mnum_yrs_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot_num_years_10fold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myrnum_train_red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mSOM_calc_samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_zg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrnum_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrnum_train_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_yrs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-227a9bc15cee>\u001b[0m in \u001b[0;36mSOM_calc_samp\u001b[0;34m(file_zg_str, n_rows, n_columns, yrnum_test, yrnum_train_red, num_yrs_train)\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrad_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrad_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrad_cooling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_cooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0msavefig_SOM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavefig_trends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuptitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult_test_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                         data_yr_reshaped_train, vmin, vmax, step, lat_str, lon_str, units, mdl_ens_str, train_input = False, JJA_days=JJA_days, save_SOM_str=savefig_SOM)\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;31m#print(\"use trained SOM to calculate cv dataset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-227a9bc15cee>\u001b[0m in \u001b[0;36msave_SOM_data\u001b[0;34m(zg_file, yrst, yrend, season, region, init, neigh, std, ep, rad_0, rad_N, rad_cooling, scale_0, scale_N, scale_cooling, savefig_title, savefig_trends, n_rows, n_columns, samp, zg_str, colormap_str, suptitle, mult_test_method, data_yr_reshaped, vmin, vmax, step, lat_str, lon_str, units, mdl, train_input, som_yr, JJA_days, save_SOM_str, save_SOM_trends_str)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     da_xr_trend, all_occur = saveSOMTrends(som_yr, dates, n_rows, n_columns, savefig_trends, colormap_str,\n\u001b[0;32m---> 73\u001b[0;31m                                 mult_test_method, mdl, train_input=train_input, bmus=bmus, JJA_days=JJA_days, yrst=yrst, yrend=yrend, samp=samp)#, save_SOM_trends_str=save_SOM_trends_str)\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mda_xr_trend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_occur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msom_yr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-227a9bc15cee>\u001b[0m in \u001b[0;36msaveSOMTrends\u001b[0;34m(som_yr, dates, n_rows, n_columns, savefig_trends, colormap_str, mult_test_method, mdl, train_input, bmus, JJA_days, yrst, yrend, samp, plot)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0maxes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time series of circulation trends \\n {mdl} {yrst}-{yrend}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavefig_trends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m#####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2261\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2264\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# if toolbar:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m#     toolbar.set_cursor(cursors.WAIT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1493\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2633\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_wrap_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    298\u001b[0m         tmp, lp_h, lp_bl = renderer.get_text_width_height_descent('lp',\n\u001b[1;32m    299\u001b[0m                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                                                          ismath=False)\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0moffsety\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_bl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmt3718/anaconda3/envs/odin/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#comment out the rest of the files dpeending on which you want to run\n",
    "#UKESM files\n",
    "file_zg_str = \"/rds/general/user/cmt3718/home/data/cmip6/UKESM1-0-LL/piControl/r1i1p1f2/zg/500zg_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_19600101-20601230_r180x91_LTDManom_EUR_JJAextd_dtrnd.nc\"\n",
    "# file_zg_str = \"/rds/general/user/cmt3718/home/data/cmip6/UKESM1-0-LL/piControl/r1i1p1f2/psl/psl_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_19600101-20601230_r180x91_LTDManom_EUR_JJAextd_dtrnd.nc\"\n",
    "# file_zg_str = \"/rds/general/project/carl_phd/live/carl/data/cmip6/UKESM1-0-LL/piControl/day/r1i1p1f2/rel_vort/500xi_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_1960-2060_r180x91_latcorr_EUR_LTDManom_JJAextd.nc\"\n",
    "\n",
    "\n",
    "#ERA5 files\n",
    "# file_zg_str = \"/rds/general/project/carl_phd/live/carl/data/era5/day/zg/LTDM/z_timedtrnd_ERA5_1979-2019_EUR_JJAextd_LTDMdaymean_anom_sort.nc\"\n",
    "# file_zg_str = \"/rds/general/project/nowack_graven/live/carl/era5/mean_sea_level_pressure/mslp_ERA5_1979-2019_EUR_JJAextd_LTDMdaymean_anom.nc\"\n",
    "# file_zg_str = \"/rds/general/user/cmt3718/home/pv_350pt_era5_1979-2019_1x1_tot_3hr_daymean_ydayavg_LTDManom_invlat_JJAextd.nc\"\n",
    "# file_zg_str = \"/rds/general/project/carl_phd/live/carl/data/era5/day/pv/isentropes/pv_330pt_era5_1979-2019_1x1_EUR_daymean_invlat_LTDManom_JJAextd2.nc\"\n",
    "# file_zg_str = \"/rds/general/project/carl_phd/live/carl/data/era5/day/rel_vort/500xi_era5_day_1979-2019_1x1_EUR_LTDManom_invlat.nc\"\n",
    "# file_zg_str = \"/rds/general/project/nowack_graven/live/carl/pv_era5/vpv_1x1_day_150-500hPa_hires_1979-2019_LTDManom_JJAextd_EUR.nc\"\n",
    "\n",
    "\n",
    "#files todo:\n",
    "###setup theta on PV=2\n",
    "\n",
    "#\"/rds/general/user/cmt3718/ephemeral/cmip6/UKESM1-0-LL/piControl/r1i1p1f2/relvort/500xi_day_UKESM1-0-LL_piControl_r1i1p1f2_gn_1960-2060_r180x91_latcorr_EUR_LTDManom_JJAextd_reshaped.nc\"\n",
    "\n",
    "\n",
    "###setup one other files for UKESM1-0-LL: vort anom 500hPa\n",
    "\n",
    "if \"era5\" in file_zg_str:\n",
    "    mip = \"era5\"\n",
    "    yrnum_test = 3\n",
    "    tot_num_years_10fold = 37\n",
    "else:\n",
    "    mip = \"UKESM1-0-LL\"\n",
    "    yrnum_test = 10\n",
    "    tot_num_years_10fold = 91\n",
    "    \n",
    "#yrnum_test = 10\n",
    "yrnum_train_red = 0#if 0, train on 37 years, if 10 train on 27 years etc\n",
    "rowcols_arr = [(2, 1), (3, 1), (2, 2), (5, 1), (3, 2), (7, 1), (4, 2), (3, 3), (5, 2), (11, 1), (4, 3), (13, 1), (7, 2), (5, 3), (4, 4), (17, 1), (6, 3),\n",
    " (19, 1), (5, 4), (7, 3), (11, 2), (23, 1), (6, 4), (5, 5), (13, 2), (9, 3), (7, 4), (29, 1), (6, 5), (31, 1), (8, 4), (33, 1), (17, 2),\n",
    "               (7, 5), (6, 6), (37, 1), (19, 2), (39, 1), (8, 5), (41, 1)]\n",
    "\n",
    "rowcols_arr = [(5, 4)]\n",
    "\n",
    "for yrnum_train_red in range(,91):#range(10,91,10):#range(0,92):\n",
    "\tfor nrow, ncol in rowcols_arr:\n",
    "    \t\tnum_yrs_train = tot_num_years_10fold-yrnum_train_red\n",
    "    \t\tSOM_calc_samp(file_zg_str, nrow, ncol, yrnum_test, yrnum_train_red, num_yrs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:odin]",
   "language": "python",
   "name": "conda-env-odin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
